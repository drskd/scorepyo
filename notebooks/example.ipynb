{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Example : Breast cancer dataset**\n",
    "\n",
    "\n",
    "## Context\n",
    "**Risk-score model** are one of the most explicit/explanable model, and are used in psychology, medicine or justice.  \n",
    "The score of such model is computed via a sum of points, which are defined for each binary feature.  \n",
    "For each possible score value, risk-score model gives a probability of belonging to the positive class.\n",
    "\n",
    "----\n",
    "\n",
    "This notebook displays the usage of the scorepyo package on the breast cancer dataset.\n",
    "\n",
    "It shows two different components:\n",
    "* Automatic feature binarizer\n",
    "* Score card model\n",
    "\n",
    "### Automatic feature binarizer\n",
    "A risk-score type model can only be constructed based on binary features.  In most cases, datasets are constructed with a mix of continuous, categorical and binary features.  \n",
    "From there, we either manually engineer the binary features, or we can automatically construct them.\n",
    "\n",
    "A risk-score model is an additive model, therefore we need to craft binary features such that they help to predict by adding their contribution, modulo a coefficient. This corresponds to General Additive Model (GAM), that's why The `AutomaticBinaryFeaturizer` class is based on a GAM that predicts the binary target.  \n",
    "The GAM used is an Explainable Boosting Machine (EBM), as EBM are good candidates for such a task. Indeed the individual feature function in EBMs is a single-feature tree. Binary features can be extracted by using the feature value intervals used to construct each single-feature tree. \n",
    "\n",
    "### Score card model\n",
    "The scorepyo package aims to provide several ways to construct a risk-score model. \n",
    "\n",
    "The first one implemented is via the `OptunaScoreCard` class. This class leverages the efficient sampling abilities of Optuna to select both binary features and their associated points amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "data = load_breast_cancer()\n",
    "data_X, y = data.data, data.target\n",
    "\n",
    "X = pd.DataFrame(data=data_X, columns = data.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create artificial categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['category'] = np.where(X['mean smoothness'] <=0.1,'A','B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create unknown category in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['category']='C'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create automatically binary features \n",
    "\n",
    "The bnary feature creation is based on train dataset to detect them.  \n",
    "The train and tests dataset are then transformed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'scorepyo' has no attribute 'exceptions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [6], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m binarizer \u001b[39m=\u001b[39m AutomaticBinaryFeaturizer(max_number_binaries_by_features\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,keep_negative\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m binarizer\u001b[39m.\u001b[39mfit(X_train,y_train, categorical_features\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, to_exclude_features\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m X_train_binarized, df_info \u001b[39m=\u001b[39m binarizer\u001b[39m.\u001b[39;49mtransform(X_train)\n\u001b[0;32m      8\u001b[0m X_test_binarized, _ \u001b[39m=\u001b[39m binarizer\u001b[39m.\u001b[39mtransform(X_test)\n",
      "File \u001b[1;32m~\\Documents\\Private\\scorepyo\\scorepyo\\core_module\\scorepyo\\binary_featurizer.py:173\u001b[0m, in \u001b[0;36mAutomaticBinaryFeaturizer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ebm\u001b[39m.\u001b[39mhas_fitted_ \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m check_is_fitted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_one_hot_encoder)):\n\u001b[0;32m    171\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mAutomaticFeatureBinarizer has not been fitted.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 173\u001b[0m dict_check_continuous_features \u001b[39m=\u001b[39m {\n\u001b[0;32m    174\u001b[0m     c: pa\u001b[39m.\u001b[39mColumn(checks\u001b[39m=\u001b[39m[scorepyo\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mNumericCheck()])\n\u001b[0;32m    175\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_continuous_features\n\u001b[0;32m    176\u001b[0m }\n\u001b[0;32m    178\u001b[0m dict_check_other_features \u001b[39m=\u001b[39m {\n\u001b[0;32m    179\u001b[0m     c: pa\u001b[39m.\u001b[39mColumn()\n\u001b[0;32m    180\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_categorical_features \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_exclude_features\n\u001b[0;32m    181\u001b[0m }\n\u001b[0;32m    183\u001b[0m dataframe_schema \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mDataFrameSchema(\n\u001b[0;32m    184\u001b[0m     {\n\u001b[0;32m    185\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdict_check_continuous_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m     strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# Enable check of other columns in the dataframe\u001b[39;00m\n\u001b[0;32m    189\u001b[0m )\n",
      "File \u001b[1;32m~\\Documents\\Private\\scorepyo\\scorepyo\\core_module\\scorepyo\\binary_featurizer.py:174\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ebm\u001b[39m.\u001b[39mhas_fitted_ \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m check_is_fitted(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_one_hot_encoder)):\n\u001b[0;32m    171\u001b[0m     \u001b[39mraise\u001b[39;00m NotFittedError(\u001b[39m\"\u001b[39m\u001b[39mAutomaticFeatureBinarizer has not been fitted.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m dict_check_continuous_features \u001b[39m=\u001b[39m {\n\u001b[1;32m--> 174\u001b[0m     c: pa\u001b[39m.\u001b[39mColumn(checks\u001b[39m=\u001b[39m[scorepyo\u001b[39m.\u001b[39;49mexceptions\u001b[39m.\u001b[39mNumericCheck()])\n\u001b[0;32m    175\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_continuous_features\n\u001b[0;32m    176\u001b[0m }\n\u001b[0;32m    178\u001b[0m dict_check_other_features \u001b[39m=\u001b[39m {\n\u001b[0;32m    179\u001b[0m     c: pa\u001b[39m.\u001b[39mColumn()\n\u001b[0;32m    180\u001b[0m     \u001b[39mfor\u001b[39;00m c \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_categorical_features \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_to_exclude_features\n\u001b[0;32m    181\u001b[0m }\n\u001b[0;32m    183\u001b[0m dataframe_schema \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39mDataFrameSchema(\n\u001b[0;32m    184\u001b[0m     {\n\u001b[0;32m    185\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdict_check_continuous_features,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    188\u001b[0m     strict\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,  \u001b[39m# Enable check of other columns in the dataframe\u001b[39;00m\n\u001b[0;32m    189\u001b[0m )\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'scorepyo' has no attribute 'exceptions'"
     ]
    }
   ],
   "source": [
    "from scorepyo.binary_featurizer import AutomaticBinaryFeaturizer\n",
    "\n",
    "\n",
    "binarizer = AutomaticBinaryFeaturizer(max_number_binaries_by_features=3,keep_negative=True)\n",
    "binarizer.fit(X_train,y_train, categorical_features='auto', to_exclude_features=None)\n",
    "\n",
    "X_train_binarized, df_info = binarizer.transform(X_train)\n",
    "X_test_binarized, _ = binarizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display binarized train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_binarized.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display information from binarizer\n",
    "\n",
    "The binarizer also outputs a dataframe containing information about the binarizer. \n",
    "This information can be later used to for the display of the `OptunaScoreCard` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train ScoreCard model\n",
    "\n",
    "The ScoreCard models can take 4 parameters:\n",
    "* `nb_max_features` : number of maximum binary features to use for the score card\n",
    "* `min_point_value` : minimum possible number of points for each binary feature\n",
    "* `max_point_value` : maximum possible number of points for each binary feature\n",
    "* `df_info`         : optional dataframe containing the correspondance between original feature and the binary feature. It must contain 2 columns *feature* and *binary_feature*.\n",
    "\n",
    "Since the `OptunaScoreCard` model is based on Optuna, we can also pass specific optuna optimize function parameters via a dictionnary in the  `optuna_optimize_params` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scorepyo.models import OptunaScoreCard\n",
    "\n",
    "\n",
    "scorepyo_model = OptunaScoreCard(nb_max_features=4, min_point_value=-1, max_point_value=2, df_info=df_info['feature'].reset_index())\n",
    "\n",
    "scorepyo_model.fit(X_train_binarized, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the summary of the score card model\n",
    "\n",
    "The summary of the score card built by the model.  \n",
    "\n",
    "It displays two elements :\n",
    "* Feature-point card : Points for each selected binary feature\n",
    "* Score card : Scores (=sum of points) with their associated probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorepyo_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision-Recall curve on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "\n",
    "y_proba = scorepyo_model.predict_proba(X_test_binarized)[:, 1].reshape(-1,1)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test.astype(int), y_proba)\n",
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "plt.plot(recall, precision)\n",
    "average_precision = np.round(average_precision_score(y_test.astype(int),y_proba),3)\n",
    "title_PR_curve = f'Average precision : \\n{average_precision}'\n",
    "plt.title(title_PR_curve)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('env_scorepyo_ci')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c47ebd8c130fa83766bfb45686b451c5107ed1c8be3add72649a522910c78a57"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
